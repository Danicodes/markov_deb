{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: latin-1\n",
    "import sys\n",
    "import markovify\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.data.path.append('./nltk_data/') # Resolving Heroku issue, should look for any missing corpus under this path, and hopefully not crash\n",
    "\n",
    "\n",
    "# Extract text from csv; put into string\n",
    "\n",
    "class Debate:\n",
    "    def __init__(self, speaker1, speaker2):\n",
    "        self.speaker1 = speaker1\n",
    "        self.speaker2 = speaker2\n",
    "\n",
    "        self.debate_csv = './debate.csv'\n",
    "        \n",
    "        self.speaker1_string = self._csv_to_str(self.debate_csv, self.speaker1)\n",
    "        self.speaker2_string = self._csv_to_str(self.debate_csv, self.speaker2)\n",
    "        \n",
    "        self.speaker1_model = self.string_to_markov_chains(self.speaker1_string)\n",
    "        self.speaker2_model = self.string_to_markov_chains(self.speaker2_string)\n",
    "        \n",
    "    def _csv_to_str(self, input_csv, speaker):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        debate_csv = pd.read_csv(input_csv)\n",
    "        debate_speaker = debate_csv[debate_csv[\"Speaker\"] == speaker][\"Text\"]\n",
    "\n",
    "        speaker_text = \"\"\n",
    "        for line in debate_speaker:\n",
    "            speaker_text += line\n",
    "        \n",
    "        return speaker_text\n",
    "    \n",
    "    def string_to_markov_chains(self, input_string):\n",
    "        \"\"\"\n",
    "        Create a markov chain from a string of text\n",
    "     \n",
    "        param: (string) input_string \n",
    "        return: a markovify object\n",
    "        \"\"\"\n",
    "\n",
    "        markov_chain = markovify.Text(input_string)\n",
    "    \n",
    "        return markov_chain\n",
    "    \n",
    "    def _markovify_speaker(self, speaker):\n",
    "        speaker_corpus = self.debate_csv[self.debate_csv[\"Speaker\"] == speaker][\"Text\"]\n",
    "        speaker_string = \"\".join(speaker_corpus)\n",
    "        speaker_model = markovify.Text(speaker_string)\n",
    "\n",
    "        return speaker_model\n",
    "\n",
    "    def generate_banter(self, short_sentence=True, sentence_size=140):\n",
    "        return_banter = \"\"\n",
    "\n",
    "        if short_sentence:\n",
    "            short_speaker1 = self.speaker1_model.make_short_sentence(sentence_size)\n",
    "            short_speaker2 = self.speaker2_model.make_short_sentence(sentence_size)\n",
    "\n",
    "            return_banter += \"{}: {}\\n\".format(self.speaker1, short_speaker1) + \\\n",
    "                             \"{}: {}\\n\".format(self.speaker2, short_speaker2)\n",
    "\n",
    "        else:\n",
    "            reg_speaker1 = self.markovify_speaker1_corpus.make_sentence()\n",
    "            reg_speaker2 = self.markovify_speaker2_corpus.make_sentence()\n",
    "\n",
    "            return_banter += \"{}: {}\\n\".format(self.speaker1, reg_speaker1) + \\\n",
    "                             \"{}: {}\\n\".format(self.speaker2, reg_speaker2)\n",
    "\n",
    "        return return_banter\n",
    "\n",
    "    def banter(self, num_lines, short_sentence=True, sentence_size=140, **kwargs):\n",
    "        topics = kwargs.get('topics')\n",
    "        print(num_lines)\n",
    "        def create_banter(num_lines, short_sentence, sentence_size):\n",
    "            return_banter = \"\"\n",
    "            for i in range(num_lines):\n",
    "                banter = str(self.generate_banter(short_sentence, sentence_size))\n",
    "                return_banter += banter + \"\\n\"\n",
    "            return return_banter\n",
    "\n",
    "        # Incomplete idea\n",
    "        if topics:\n",
    "            for topic in topics:\n",
    "                print(\"Round Topic: {}\".format(topic))\n",
    "                return create_banter(num_lines, short_sentence, sentence_size)  # TODO: Edit banter to accept topics\n",
    "\n",
    "        else:\n",
    "            return create_banter(num_lines, short_sentence, sentence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_debate = Debate(\"Clinton\", \"Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['blah', 'bah', 'baldafw', 'dafjnwof']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_debate.markovify_speaker1_corpus.generate_corpus(text=\"blah bah baldafw dafjnwof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_debate.markovify_speaker1_corpus.make_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<br>Clinton: He never apologized for. <br>Trump: She doesn't like Putin because Putin has outsmarted her at every single country in history. </br></br>\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_debate.banter(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
