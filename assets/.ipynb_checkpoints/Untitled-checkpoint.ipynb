{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load markov_debate.py\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import markovify\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "\n",
    "def csv_to_string(input_csv, speaker):\n",
    "    \"\"\"\n",
    "    Extract text from csv; put into string for a speaker\n",
    "    \n",
    "    param: input_csv: (string) path to csv file\n",
    "    param: speaker: (string) name of speaker to search for in csv\n",
    "    return: (string) speaker_text string of text corresponding to a speaker\n",
    "    \"\"\"\n",
    "\n",
    "    debate_csv = pd.read_csv(input_csv)\n",
    "    debate_speaker = debate_csv[debate_csv[\"Speaker\"] == speaker][\"Text\"]\n",
    "\n",
    "    speaker_text = \"\"\n",
    "    for line in debate_speaker:\n",
    "        speaker_text += line\n",
    "\n",
    "    return speaker_text\n",
    "\n",
    "\n",
    "def string_to_markov_chains(input_string):\n",
    "    \"\"\"\n",
    "    Create a markov chain from a string of text\n",
    "     \n",
    "    param: (string) input_string \n",
    "    return: a markovify object\n",
    "    \"\"\"\n",
    "\n",
    "    markov_chain = markovify.Text(input_string)\n",
    "    \n",
    "    return markov_chain\n",
    "\n",
    "\n",
    "def generate_banter(markov_ch_1, markov_ch_2, speaker_name_1, speaker_name_2, short_sentence = True, sentence_size = 140):\n",
    "\n",
    "    return_banter = \"\"\n",
    "\n",
    "    if short_sentence:\n",
    "        short_speaker_1 = markov_ch_1.make_short_sentence(sentence_size)\n",
    "        short_speaker_2 = markov_ch_2.make_short_sentence(sentence_size)\n",
    "\n",
    "        return_banter += \"{}: \".format(speaker_name_1) + short_speaker_1 + \"\\n\" + \"{}: \".format(speaker_name_2) + short_speaker_2 + \"\\n\"\n",
    "\n",
    "    else:\n",
    "        speaker_1_sentence = markov_ch_1.make_sentence()\n",
    "        speaker_2_sentence = markov_ch_2.make_sentence()\n",
    "\n",
    "        return_banter += \"{}: \".format(speaker_name_1) + speaker_1_sentence + \"\\n\" + \"{}: \".speaker_name_2 + speaker_2_sentence + \"\\n\"\n",
    "\n",
    "    return return_banter\n",
    "\n",
    "\n",
    "def banter(num_lines, short_sentence = True, sentence_size = 140, **kwargs):\n",
    "    topics = kwargs.get('topics')\n",
    "    return_banter = \"\"\n",
    "\n",
    "    if topics:\n",
    "        for topic in topics:\n",
    "            print (\"Round Topic: {0}\").format(topic)\n",
    "            for i in range(num_lines):\n",
    "                banter = str(generate_banter(short_sentence, sentence_size))\n",
    "                return_banter += banter + \"\\n\"\n",
    "    else:\n",
    "        for i in range(num_lines):\n",
    "                banter = str(generate_banter(short_sentence, sentence_size))\n",
    "                return_banter += banter\n",
    "\n",
    "    return (\"\\n\" + return_banter)\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_csv = \"./debate.csv\"\n",
    "    clinton_text = csv_to_string(input_csv, \"Clinton\")\n",
    "    trump_text = csv_to_string(input_csv, \"Trump\")\n",
    "    \n",
    "    clinton_markov = string_to_markov_chains(clinton_text)\n",
    "    trump_markov = string_to_markov_chains(trump_text)\n",
    "    \n",
    "    print generate_banter(clinton_markov, trump_markov, \"Clinton\", \"Trump\")\n",
    "    print banter(4, topics = [\"Race\"])\n",
    "    \n",
    "    #sentence = markov_clinton.make_sentence()\n",
    "    #test = nltk.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "# If topics are present:\n",
    "#     For each topic generate sentence based on the topic\n",
    "#     Generate rebutal based on topic/s from previous\n",
    "#     Follow general sentence flow\n",
    "# If topics are present:\n",
    "#     num_lines will be number of lines of debate for EACH topic\n",
    "#\n",
    "# GENERAL for sentence flow -\n",
    "# Extract nouns/get rid of closed-class words from first generated sentence; Generate next sentence (rebuttal) based on nouns/topics from previous; 16\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "\n",
    "#\"\"\" MODULE CHANGE\n",
    "#def make_sentence_including(words):\n",
    "\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "#banter(1, topics = [\"Race\", \"Grace\", \"Mace\"])\n",
    "\n",
    "#sentence = markov_clinton.make_sentence()\n",
    "#test = nltk.word_tokenize(sentence)\n",
    "\n",
    "#nltk.pos_tag(sentence)\n",
    "\n",
    "#nltk.word_tokenize() nltk.tokenize()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_banter() takes at least 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a605938eabee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mbanter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-1cfe20d0fe78>\u001b[0m in \u001b[0;36mbanter\u001b[0;34m(num_lines, short_sentence, sentence_size, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mbanter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_banter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mreturn_banter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbanter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_banter() takes at least 4 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "print banter(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton: That's what we want to appoint Supreme Court that understands because you're wealthy and corporations to pay for everything I'm proposing.\n",
      "Trump: They know it better than anybody that's ever run for the presidency of Barack Obama, his hometown, you have to lose?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
